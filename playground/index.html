<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Franck Davoine</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
  </head>
  <body>
    <section class="bg-body-secondary">
      <div class="container text-center p-4">
        <h1><p class="text-primary">Franck Davoine</p></h1>
        <h4 class="text-secondary">CNRS, INSA Lyon, UCBL, Centrale Lyon, Univ Lyon 2, LIRIS Lab. (UMR 5205), F-69621 Villeurbanne</h3>
      </div>
    </section>
        <section>
        <div class="container p-4">
          <hr class="border border-danger border-2 opacity-50">
          <h5>Abstract</h5>
          <p>Event cameras capture changes of illumination in the observed scene rather than accumulating light to create images. Thus, they allow for applications under high-speed motion and complex lighting conditions, where traditional framebased sensors show their limits with blur and over- or under-exposed pixels. Thanks to these unique properties, they represent nowadays an highly attractive sensor for ITS-related applications. Event-based optical flow (EBOF) has been studied following the rise in popularity of these neuromorphic cameras. The recent arrival of high-definition neuromorphic sensors, however, challenges the existing approaches, because of the increased resolution of the events pixel array and a much higher throughput. As an answer to these points, we propose an optimized framework for computing optical flow in real-time with both low- and high-resolution event cameras. We formulate a novel dense representation for the sparse events flow, in the form of the “inverse exponential distance surface”. It serves as an interim frame, designed for the use of proven, state-of-the-art frame-based optical flow computation methods. We evaluate our approach on both low- and high-resolution driving sequences, and show that it often achieves better results than the current state of the art, while also reaching higher frame rates, 250Hz at 346x260 pixels and 77Hz at 1280x720 pixels.</p>
          <hr class="my-4">
          <h5>Citation</h5>
          <pre class="bg-body-secondary px-3 py-3"><code>@article{Brebion2022RealTimeOF,
<!-- -->  title={Real-Time Optical Flow for Vehicular Perception With Low- and High-Resolution Event Cameras},
<!-- -->  author={Vincent Brebion and Julien Moreau and Franck Davoine},
<!-- -->  journal={IEEE Transactions on Intelligent Transportation Systems},
<!-- -->  year={2022},
<!-- -->  volume={23},
<!-- -->  number={9},
<!-- -->  pages={15066-15078}
<!-- -->}</code></pre>
          <hr class="my-4">
          <h5>Acknowledgment</h5>
          <p>This work is supported in part by the Hauts-de-France Region and in part by the SIVALab Joint Laboratory (Renault Group - Université de technologie de Compiègne (UTC) - Centre National de la Recherche Scientifique (CNRS)).</p>
      </div>
    </section>
    <section>
      <div class="container p-4">
        <h5>Short resume</h5>
        <div class="container">
          <ul class="list-group list-group-flush">
            <li class="list-group-item">Since 2023: CNRS Senior Researcher (Directeur de recherche) at <a href="https://liris.cnrs.fr/en" class="link-primary">LIRIS</a>. CNRS Informatics - Institute for Information Sciences and Technologies (INS2I).
              Coordinator of the <a href="https://liris.cnrs.fr/en/team/imagine" class="link-primary">Imagine</a> research team. 
              Lab. Seminar Coordinator.
              Member of the Environmental Transition working group.
            </li>
            <li class="list-group-item">From 2014 to 2023: CNRS Researcher at Heudiasyc, SyRI team – Robotic Systems in Interaction.</li>
            <li class="list-group-item">From 2011 to 2014: CNRS Researcher at LIAMA - Sino-European Laboratory of Computer Science, Automation and Applied Mathematics, in Beijing, P.R. China. Member of the Key Laboratory of Machine Perception (Ministry of Education), Peking University.</li>
            <li class="list-group-item">From 2007 to 2010: CNRS Researcher at LIAMA - Sino-European Laboratory of Computer Science, Automation and Applied Mathematics, in Beijing, P.R. China. Member of the Institute of Automation, Chinese Academy of Sciences (CASIA).</li>
            <li class="list-group-item">From 2002 to 2007: CNRS Researcher (Chargé de recherche) at Heudiasyc, CNRS / UTC, France.</li>
            <li class="list-group-item">From 1997 to 2001: Associate Professor (Maître de conférences) at Heudiasyc, CNRS / UTC, France.</li>
            <li class="list-group-item">From 1996 to 1997: Postdoctoral research fellow (18 months), University of Linköping, Sweden.</li>
            <li class="list-group-item">1995: Laureate of the Grenoble INP PhD Thesis Prize (discipline 'Signal, image and speech processing'), Université Grenoble Alpes, France.</li>
          </ul>
        </div>
      </div>
    </section>
    <section>
      <div class="container p-4">
        <div class="container">
          <a class="btn btn-primary" href="research" role="button">Research</a>
          <a class="btn btn-primary" href="publications" role="button">Publications</a>
          <a class="btn btn-primary" href="students" role="button">Students</a>
        </div>
      </div>
    </section>
  </body>
</html>
